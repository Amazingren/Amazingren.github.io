<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>News</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 20px;
      background: #f9f9f9;
    }

    .news-card {
      width: "95%";
      background: #fff;
      border: 1px solid #ccc;
      border-radius: 10px;
      box-shadow: 0 4px 6px rgba(0,0,0,0.1);
      overflow: hidden; /* è®©æ ‡é¢˜å’Œå†…å®¹ä¿æŒä¸€ä¸ªæ•´ä½“ */
    }

    .news-heading {
      font-size: 20px;
      font-weight: bold;
      padding: 12px;
      text-align: center;
      border-bottom: 1px solid #ccc;
      background: #fafafa;
    }

    .news-container {
      height: 200px;
      overflow-y: auto;                /* ä»…å†…å®¹æ»šåŠ¨ */
      scrollbar-gutter: stable both-edges; /* è®©ä¸¤è¾¹å¯¹ç§° */
      box-sizing: border-box;
      padding: 15px;
      font-size: 12px;
    }

    /* å…¼å®¹æ—§æµè§ˆå™¨ï¼šé¢„ç•™æ»šåŠ¨æ¡å®½åº¦ */
    @supports not (scrollbar-gutter: stable) {
      .news-container { padding-right: 28px; }
    }

    .news-container ul {
      list-style-type: none;
      padding: 0;
      margin: 0;
    }

    .news-container li {
      margin-bottom: 12px;
      line-height: 1.5;
    }

    .news-container li strong {
      color: #b22222;
    }
  </style>
</head>
<body>
  <div class="news-card">
    <div class="news-heading">News</div>
    <div class="news-container">
      <ul>
        <li>ğŸ¾2025/09: Our work "SceneSplat++" has been accepted as Oral by <strong>NeurIPS2025</strong>,  congrats and thx to our team!</li>
        <li>ğŸ¾2025/06: We have 2 papers accepted by <strong>ICCV2025</strong>, one Oral (ğŸ“£, SceneSplat) and one Highlight (ğŸ’¡, ObjectRelator), congrats and grande thx to our team! </li>
        <li>ğŸ¾2024/12: Our paper "HYRE: Hybrid Regressor for 3D Human Pose and Shape Estimation" has been accepted to <strong>TIP</strong>.</li>
        <li>ğŸ¾2024/11: Our paper "ShapeSplat: A Large-scale Dataset of Gaussian Splats and Their Self-Supervised Pretraining" has been accepted to <strong>3DV2025</strong>.</li>
        <li>ğŸ¾2024/09: Our paper "Sharing Key Semantics in Transformer Makes Efficient Image Restoration" has been accepted to <strong>NeurIPS2024</strong>.</li>
        <li>ğŸ¾2024/09: Our paper "Bringing masked autoencoders explicit contrastive properties for point cloud self-supervised learning" has been accepted to <strong>ACCV2024</strong>.</li>
        <li>ğŸ¾2024/08: Our paper "A Pure MLP-Mixer-based GAN Framework for Guided Image Translation" has been accepted to <strong>PR2024</strong>.</li>
        <li>ğŸ“Œ2024/03: I joined <a href="https://insait.ai/" target="_blank">INSAIT</a> in Sofia as a visiting Ph.D. student.</li>
        <li>ğŸ’¥2024/02: We are organizing the NTIRE2024 Efficient Super-Resolution Challenge! Come and join via: <a href="https://cvlai.net/ntire/2024/" target="_blank">NTIRE2024</a></li>
        <li>ğŸ¾2024/01: Our paper "A survey on 3d skeleton-based action recognition using learning method" has been accepted as oral by <strong>CBS2024</strong>.</li>
        <li>ğŸ¾2023/11: Our paper "Modiff: Action-conditioned 3d motion generation with denoising diffusion probabilistic models" has been accepted as oral by <strong>ICASSP2024</strong>.</li>
        <li>ğŸ¾2023/08: Our paper "Spatio-Temporal Graph Diffusion for Text-Driven Human Motion Generation" has been accepted as oral by <strong>BMVC2023</strong>.</li>
        <li>ğŸ¾2023/08: Our paper "Cloth Interactive Transformer for Virtual Try-On" has been accepted by <strong>ACM ToMM 2023</strong>.</li>
        <li>ğŸ“Œ2023/08: I joined the <a href="https://vision.ee.ethz.ch/" target="_blank">Computer Vision Lab (CVL)</a> of <a href="https://ethz.ch/en.html" target="_blank">ETH ZÃ¼rich</a> in Switzerland as a 6-month academic visiting Ph.D. Student.</li>
        <li>ğŸ¾2023/03: Our paper "Masked Jigsaw Puzzle: A Versatile Position Embedding for Vision Transformers" has been accepted by <strong>CVPR2023</strong>.</li>
        <li>ğŸ¾2023/02: Our paper "PI-Trans: Parallel-ConvMLP and Implicit-Transformation Based GAN for Cross-View Image Translation" has been accepted by <strong>ICASSP2023</strong>.</li>
        <li>ğŸ¾2022/10: Our paper "Deep Unsupervised Key Frame Extraction for Efficient Video Classification" has been accepted by <strong>TOMM2022</strong>.</li>
        <li>ğŸ¾2021/10: Our paper "Cascaded Cross MLP-Mixer GANs for Cross-View Image Translation" has been accepted by <strong>BMVC2021</strong> as oral.</li>
      </ul>
    </div>
  </div>
</body>
</html>
